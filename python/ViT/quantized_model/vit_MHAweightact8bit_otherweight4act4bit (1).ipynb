{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8be583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from torchao.quantization import Int4DynamicActivationInt4WeightConfig, Int8WeightOnlyConfig ,Int8DynamicActivationInt8WeightConfig,  quantize_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afcbf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.ViT_B_16_Weights.DEFAULT\n",
    "transform = weights.transforms()\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"dataset/train\", transform=transform)\n",
    "val_dataset   = datasets.ImageFolder(\"dataset/val\", transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(\"dataset/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e38c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca0eff7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"model_full.pth\", weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1277bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) モジュール差し替え用ヘルパ ---\n",
    "def replace_nondynamic_linear_with_nn_linear(model):\n",
    "    \"\"\"\n",
    "    model 中のクラス名が 'NonDynamicallyQuantizableLinear' のモジュールを\n",
    "    通常の nn.Linear に置き換える。\n",
    "    \"\"\"\n",
    "    # collect (full_name, module) first to avoid mutating while iterating\n",
    "    targets = []\n",
    "    for name, module in model.named_modules():\n",
    "        if module.__class__.__name__ == \"NonDynamicallyQuantizableLinear\":\n",
    "            targets.append((name, module))\n",
    "\n",
    "    if not targets:\n",
    "        print(\"No NonDynamicallyQuantizableLinear found.\")\n",
    "        return 0\n",
    "\n",
    "    for full_name, old_mod in targets:\n",
    "        # create new linear with same shape & bias\n",
    "        in_f = getattr(old_mod, \"in_features\", None)\n",
    "        out_f = getattr(old_mod, \"out_features\", None)\n",
    "        has_bias = getattr(old_mod, \"bias\", None) is not None\n",
    "\n",
    "        if in_f is None or out_f is None:\n",
    "            print(f\"Skipping {full_name}: cannot find in/out features.\")\n",
    "            continue\n",
    "\n",
    "        new_mod = nn.Linear(in_f, out_f, bias=has_bias)\n",
    "        # copy weights and bias (cast to float32 to be safe)\n",
    "        try:\n",
    "            # some custom modules store weight as `.weight` Parameter\n",
    "            new_mod.weight.data.copy_(old_mod.weight.data.to(new_mod.weight.dtype))\n",
    "            if has_bias:\n",
    "                new_mod.bias.data.copy_(old_mod.bias.data.to(new_mod.bias.dtype))\n",
    "        except Exception as e:\n",
    "            # fallback: try to read .weight.numpy or .weight.clone()\n",
    "            print(f\"Warning copying params for {full_name}: {e}\")\n",
    "\n",
    "        # find parent module and attribute name\n",
    "        name_parts = full_name.split(\".\")\n",
    "        parent = model\n",
    "        for p in name_parts[:-1]:\n",
    "            parent = getattr(parent, p)\n",
    "        attr_name = name_parts[-1]\n",
    "\n",
    "        # setattr on parent\n",
    "        setattr(parent, attr_name, new_mod)\n",
    "        print(f\"Replaced {full_name} -> nn.Linear({in_f},{out_f}, bias={has_bias})\")\n",
    "\n",
    "    return len(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ade67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fp32 = copy.deepcopy(model).to(torch.float32)\n",
    "model_fp32.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df9d5fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced encoder.layers.encoder_layer_0.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_1.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_2.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_3.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_4.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_5.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_6.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_7.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_8.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_9.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_10.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n",
      "Replaced encoder.layers.encoder_layer_11.self_attention.out_proj -> nn.Linear(768,768, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_nondynamic_linear_with_nn_linear(model_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be2f223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mixed_quantization(model):\n",
    "\n",
    "    MHA_qcfg = Int8DynamicActivationInt8WeightConfig()\n",
    "    othre_qcfg = Int4DynamicActivationInt4WeightConfig()\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # MultiheadAttention の out_proj は Int8 に量子化（in-place）\n",
    "        if isinstance(module, nn.MultiheadAttention):\n",
    "            outp = module.out_proj\n",
    "            if isinstance(outp, nn.Linear):\n",
    "                # quantize_ は in-place 変換で None を返すので代入しないこと！\n",
    "                quantize_(outp, MHA_qcfg)\n",
    "                print(f\"{name}.out_proj -> Int8 (in-place)\")\n",
    "        # その他の Linear は Int4 に量子化（in-place）\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            # out_proj を上書きしてしまわないよう名前チェック。ただし out_proj は MultiheadAttention 部分で既に処理済み。\n",
    "            if name.endswith(\"out_proj\"):\n",
    "                # MultiheadAttention の out_proj は上で処理済み or out_proj が別オブジェクトの場合があるのでスキップ\n",
    "                continue\n",
    "            quantize_(module, othre_qcfg)\n",
    "            print(f\"{name} -> Int4 (in-place)\")\n",
    "\n",
    "     # 簡単な整合チェック: MultiheadAttention の out_proj が None になっていないか確認\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.MultiheadAttention):\n",
    "            if module.out_proj is None:\n",
    "                raise RuntimeError(f\"Error: {name}.out_proj is None after quantization!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "039c40f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.layers.encoder_layer_0.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_0.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_0.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_1.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_1.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_2.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_2.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_3.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_3.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_4.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_4.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_5.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_5.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_6.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_6.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_7.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_7.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_8.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_8.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_9.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_9.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_10.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_10.mlp.3 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj -> Int8 (in-place)\n",
      "encoder.layers.encoder_layer_11.mlp.0 -> Int4 (in-place)\n",
      "encoder.layers.encoder_layer_11.mlp.3 -> Int4 (in-place)\n",
      "heads.head -> Int4 (in-place)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=768, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x7373984ec820>, weight=AffineQuantizedTensor(shape=torch.Size([768, 768]), block_size=(1, 768), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([3072, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([768, 3072]), block_size=[1, 3072], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=5, weight=LinearActivationQuantizedTensor(activation=<function _int4_symm_cutlass_quant at 0x7373984ecaf0>, weight=AffineQuantizedTensor(shape=torch.Size([5, 768]), block_size=[1, 768], device=cpu, _layout=CutlassInt4PackedLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fp32 = apply_mixed_quantization(model_fp32)\n",
    "model_fp32.eval()\n",
    "\n",
    "model_fp32.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ff22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_MHAweightact8bit_otherweight4act4bit.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c58e37c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing quantized model: 100%|██████████| 14/14 [00:30<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT4 weight-only Test Accuracy: 0.6092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- テスト評価（あなたの test_loader をそのまま使ってください）---\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing quantized model\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_fp32(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"INT4 weight-only Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vit",
   "language": "python",
   "name": ".vit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
