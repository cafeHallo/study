{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8be583",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'int1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcopy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Int4DynamicActivationInt4WeightConfig, Int8WeightOnlyConfig , quantize_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karas\\Documents\\etc\\python\\.vit\\Lib\\site-packages\\torchao\\__init__.py:63\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     61\u001b[39m         logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping import of cpp extensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     64\u001b[39m     autoquant,\n\u001b[32m     65\u001b[39m     quantize_,\n\u001b[32m     66\u001b[39m )\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes, optim, quantization, swizzle, testing\n\u001b[32m     70\u001b[39m __all__ = [\n\u001b[32m     71\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdtypes\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     72\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mautoquant\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquantization\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     79\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karas\\Documents\\etc\\python\\.vit\\Lib\\site-packages\\torchao\\quantization\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkernel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     int_scaled_matmul,\n\u001b[32m      3\u001b[39m     safe_int_mm,\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautoquant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     ALL_AUTOQUANT_CLASS_LIST,\n\u001b[32m      8\u001b[39m     DEFAULT_AUTOQUANT_CLASS_LIST,\n\u001b[32m      9\u001b[39m     DEFAULT_FLOAT_AUTOQUANT_CLASS_LIST,\n\u001b[32m     10\u001b[39m     DEFAULT_INT4_AUTOQUANT_CLASS_LIST,\n\u001b[32m     11\u001b[39m     DEFAULT_SPARSE_AUTOQUANT_CLASS_LIST,\n\u001b[32m     12\u001b[39m     GEMLITE_INT4_AUTOQUANT_CLASS_LIST,\n\u001b[32m     13\u001b[39m     OTHER_AUTOQUANT_CLASS_LIST,\n\u001b[32m     14\u001b[39m     autoquant,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mGPTQ\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     Int4WeightOnlyGPTQQuantizer,\n\u001b[32m     18\u001b[39m     MultiTensor,\n\u001b[32m     19\u001b[39m     MultiTensorInputRecorder,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgranularity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     PerAxis,\n\u001b[32m     23\u001b[39m     PerGroup,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     PerToken,\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karas\\Documents\\etc\\python\\.vit\\Lib\\site-packages\\torchao\\quantization\\autoquant.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m return_and_correct_aliasing\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     AffineQuantizedTensor,\n\u001b[32m     13\u001b[39m     Float8Layout,\n\u001b[32m     14\u001b[39m     MarlinSparseLayout,\n\u001b[32m     15\u001b[39m     PlainLayout,\n\u001b[32m     16\u001b[39m     SemiSparseLayout,\n\u001b[32m     17\u001b[39m     TensorCoreTiledLayout,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Layout\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfloat8\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Float8MMConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karas\\Documents\\etc\\python\\.vit\\Lib\\site-packages\\torchao\\dtypes\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m affine_quantized_tensor_ops\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maffine_quantized_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     AffineQuantizedTensor,\n\u001b[32m      4\u001b[39m     to_affine_quantized_floatx,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     to_affine_quantized_intx_static,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfbgemm_fp8_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FbgemmFp8Tensor, to_fbgemm_fp8\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karas\\Documents\\etc\\python\\.vit\\Lib\\site-packages\\torchao\\dtypes\\affine_quantized_tensor_ops.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m return_and_correct_aliasing\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maffine_quantized_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     AffineQuantizedTensor,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfloatx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcutlass_semi_sparse_layout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     15\u001b[39m     _linear_fp8_act_fp8_weight_sparse_cutlass_check,\n\u001b[32m     16\u001b[39m     _linear_fp8_act_fp8_weight_sparse_cutlass_impl,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfloatx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfloat8_layout\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     19\u001b[39m     _linear_fp8_act_fp8_weight_check,\n\u001b[32m     20\u001b[39m     _linear_fp8_act_fp8_weight_impl,\n\u001b[32m     21\u001b[39m     _linear_fp_act_fp8_weight_check,\n\u001b[32m     22\u001b[39m     _linear_fp_act_fp8_weight_impl,\n\u001b[32m     23\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karas\\Documents\\etc\\python\\.vit\\Lib\\site-packages\\torchao\\dtypes\\affine_quantized_tensor.py:17\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     AQTTensorImpl,\n\u001b[32m     14\u001b[39m     Layout,\n\u001b[32m     15\u001b[39m     PlainLayout,\n\u001b[32m     16\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquant_primitives\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     FP8_TYPES,\n\u001b[32m     19\u001b[39m     MappingType,\n\u001b[32m     20\u001b[39m     ZeroPointDomain,\n\u001b[32m     21\u001b[39m     _choose_qparams_affine_dont_preserve_zero,\n\u001b[32m     22\u001b[39m     _choose_qparams_affine_floatx,\n\u001b[32m     23\u001b[39m     _choose_qparams_affine_tinygemm,\n\u001b[32m     24\u001b[39m     _choose_qparams_and_quantize_affine_hqq,\n\u001b[32m     25\u001b[39m     _choose_scale_float8,\n\u001b[32m     26\u001b[39m     _dequantize_affine_float8,\n\u001b[32m     27\u001b[39m     _dequantize_affine_floatx,\n\u001b[32m     28\u001b[39m     _dequantize_affine_no_zero_point,\n\u001b[32m     29\u001b[39m     _dequantize_affine_tinygemm,\n\u001b[32m     30\u001b[39m     _quantize_affine_float8,\n\u001b[32m     31\u001b[39m     _quantize_affine_floatx,\n\u001b[32m     32\u001b[39m     _quantize_affine_no_zero_point,\n\u001b[32m     33\u001b[39m     _quantize_affine_tinygemm,\n\u001b[32m     34\u001b[39m     choose_qparams_affine,\n\u001b[32m     35\u001b[39m     dequantize_affine,\n\u001b[32m     36\u001b[39m     quantize_affine,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchAOBaseTensor\n\u001b[32m     40\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karas\\Documents\\etc\\python\\.vit\\Lib\\site-packages\\torchao\\quantization\\quant_primitives.py:174\u001b[39m\n\u001b[32m    151\u001b[39m _SUB_BYTE_UINT_BOUNDS = {\n\u001b[32m    152\u001b[39m     torch.uint1: (\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m**\u001b[32m1\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m    153\u001b[39m     torch.uint2: (\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m**\u001b[32m2\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m     torch.uint7: (\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m**\u001b[32m7\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m    159\u001b[39m }\n\u001b[32m    160\u001b[39m _DTYPE_TO_BIT_WIDTH.update(\n\u001b[32m    161\u001b[39m     {\n\u001b[32m    162\u001b[39m         torch.uint1: \u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    169\u001b[39m     }\n\u001b[32m    170\u001b[39m )\n\u001b[32m    172\u001b[39m _SUB_BYTE_INT_BOUNDS.update(\n\u001b[32m    173\u001b[39m     {\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint1\u001b[49m: (-(\u001b[32m2\u001b[39m**\u001b[32m0\u001b[39m), \u001b[32m2\u001b[39m**\u001b[32m0\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m    175\u001b[39m         torch.int2: (-(\u001b[32m2\u001b[39m**\u001b[32m1\u001b[39m), \u001b[32m2\u001b[39m**\u001b[32m1\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m    176\u001b[39m         torch.int3: (-(\u001b[32m2\u001b[39m**\u001b[32m2\u001b[39m), \u001b[32m2\u001b[39m**\u001b[32m2\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m    177\u001b[39m         torch.int4: (-(\u001b[32m2\u001b[39m**\u001b[32m3\u001b[39m), \u001b[32m2\u001b[39m**\u001b[32m3\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m    178\u001b[39m         torch.int5: (-(\u001b[32m2\u001b[39m**\u001b[32m4\u001b[39m), \u001b[32m2\u001b[39m**\u001b[32m4\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m    179\u001b[39m         torch.int6: (-(\u001b[32m2\u001b[39m**\u001b[32m5\u001b[39m), \u001b[32m2\u001b[39m**\u001b[32m5\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m    180\u001b[39m         torch.int7: (-(\u001b[32m2\u001b[39m**\u001b[32m6\u001b[39m), \u001b[32m2\u001b[39m**\u001b[32m6\u001b[39m - \u001b[32m1\u001b[39m),\n\u001b[32m    181\u001b[39m     }\n\u001b[32m    182\u001b[39m )\n\u001b[32m    183\u001b[39m _DTYPE_TO_BIT_WIDTH.update(\n\u001b[32m    184\u001b[39m     {\n\u001b[32m    185\u001b[39m         torch.int1: \u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    192\u001b[39m     }\n\u001b[32m    193\u001b[39m )\n\u001b[32m    195\u001b[39m _DTYPE_TO_QVALUE_BOUNDS.update(_SUB_BYTE_UINT_BOUNDS)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karas\\Documents\\etc\\python\\.vit\\Lib\\site-packages\\torch\\__init__.py:2562\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _lazy_modules:\n\u001b[32m   2560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[34m__name__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2562\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch' has no attribute 'int1'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from torchao.quantization import Int4DynamicActivationInt4WeightConfig, Int8WeightOnlyConfig , quantize_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afcbf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.ViT_B_16_Weights.DEFAULT\n",
    "transform = weights.transforms()\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"dataset/train\", transform=transform)\n",
    "val_dataset   = datasets.ImageFolder(\"dataset/val\", transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(\"dataset/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e38c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0eff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model_full.pth\", weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) モジュール差し替え用ヘルパ ---\n",
    "def replace_nondynamic_linear_with_nn_linear(model):\n",
    "    \"\"\"\n",
    "    model 中のクラス名が 'NonDynamicallyQuantizableLinear' のモジュールを\n",
    "    通常の nn.Linear に置き換える。\n",
    "    \"\"\"\n",
    "    # collect (full_name, module) first to avoid mutating while iterating\n",
    "    targets = []\n",
    "    for name, module in model.named_modules():\n",
    "        if module.__class__.__name__ == \"NonDynamicallyQuantizableLinear\":\n",
    "            targets.append((name, module))\n",
    "\n",
    "    if not targets:\n",
    "        print(\"No NonDynamicallyQuantizableLinear found.\")\n",
    "        return 0\n",
    "\n",
    "    for full_name, old_mod in targets:\n",
    "        # create new linear with same shape & bias\n",
    "        in_f = getattr(old_mod, \"in_features\", None)\n",
    "        out_f = getattr(old_mod, \"out_features\", None)\n",
    "        has_bias = getattr(old_mod, \"bias\", None) is not None\n",
    "\n",
    "        if in_f is None or out_f is None:\n",
    "            print(f\"Skipping {full_name}: cannot find in/out features.\")\n",
    "            continue\n",
    "\n",
    "        new_mod = nn.Linear(in_f, out_f, bias=has_bias)\n",
    "        # copy weights and bias (cast to float32 to be safe)\n",
    "        try:\n",
    "            # some custom modules store weight as `.weight` Parameter\n",
    "            new_mod.weight.data.copy_(old_mod.weight.data.to(new_mod.weight.dtype))\n",
    "            if has_bias:\n",
    "                new_mod.bias.data.copy_(old_mod.bias.data.to(new_mod.bias.dtype))\n",
    "        except Exception as e:\n",
    "            # fallback: try to read .weight.numpy or .weight.clone()\n",
    "            print(f\"Warning copying params for {full_name}: {e}\")\n",
    "\n",
    "        # find parent module and attribute name\n",
    "        name_parts = full_name.split(\".\")\n",
    "        parent = model\n",
    "        for p in name_parts[:-1]:\n",
    "            parent = getattr(parent, p)\n",
    "        attr_name = name_parts[-1]\n",
    "\n",
    "        # setattr on parent\n",
    "        setattr(parent, attr_name, new_mod)\n",
    "        print(f\"Replaced {full_name} -> nn.Linear({in_f},{out_f}, bias={has_bias})\")\n",
    "\n",
    "    return len(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp32 = copy.deepcopy(model).to(torch.float32)\n",
    "model_fp32.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d5fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nondynamic_linear_with_nn_linear(model_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mixed_quantization(model):\n",
    "\n",
    "    int4_qcfg = Int4DynamicActivationInt4WeightConfig()\n",
    "    int8_qcfg = Int8WeightOnlyConfig()\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        # MultiheadAttention の out_proj は Int8 に量子化（in-place）\n",
    "        if isinstance(module, nn.MultiheadAttention):\n",
    "            outp = module.out_proj\n",
    "            if isinstance(outp, nn.Linear):\n",
    "                # quantize_ は in-place 変換で None を返すので代入しないこと！\n",
    "                quantize_(outp, int8_qcfg)\n",
    "                print(f\"{name}.out_proj -> Int8 (in-place)\")\n",
    "        # その他の Linear は Int4 に量子化（in-place）\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            # out_proj を上書きしてしまわないよう名前チェック。ただし out_proj は MultiheadAttention 部分で既に処理済み。\n",
    "            if name.endswith(\"out_proj\"):\n",
    "                # MultiheadAttention の out_proj は上で処理済み or out_proj が別オブジェクトの場合があるのでスキップ\n",
    "                continue\n",
    "            quantize_(module, int4_qcfg)\n",
    "            print(f\"{name} -> Int4 (in-place)\")\n",
    "\n",
    "     # 簡単な整合チェック: MultiheadAttention の out_proj が None になっていないか確認\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.MultiheadAttention):\n",
    "            if module.out_proj is None:\n",
    "                raise RuntimeError(f\"Error: {name}.out_proj is None after quantization!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp32 = apply_mixed_quantization(model_fp32)\n",
    "model_fp32.eval()\n",
    "\n",
    "model_fp32.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_MHAweight8bit_otherweightact4bit.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- テスト評価（あなたの test_loader をそのまま使ってください）---\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing quantized model\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_fp32(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print(f\"INT4 weight-only Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
